Компьютер воспринимает все данные в виде [двоичного кода](двоичный%20код), в том числе из цифры

## Представление целых чисел
#### 1. Натуральные числа (unsignet)
Диапазон значений: 
$N=\begin{cases}N\geqslant0\\ N<2^N\end{cases}$ - где N число бит. $2^N-1$ - Максимальное число
`Пример: 13 в 8 битной системе, это - 1101`
#### 2. Целые числа (signet)
Есть три системы представления отрицательных чисел: 
1. Прямой код (sign-magnitude) - меняем последний бит числа в системе разрядности на 1, для отрицательных чисел, тем самым отмечая число как "отрицательное"
	Данная система используется для обучения, но в компьютере числа так не хранятся
	`Пример: 33 (16 bit) = 100001; -33 (16 bit) = 1000000000100001`
2. Обратный код (one\`s complement) - реверсивно записываем биты, для отрицательных чисел, меняя 0 на 1 и наоборот. 
	Данная система так же не используется в компьютере
	`Пример: 33 (16 bit) = 100001; -33 (16 bit) = 1111111111011110`
3. Дополнительный код (two\`s  compliment) - реверсивно записываем биты, для отрицательных чисел, меня 0 на 1 и наоборот, а так же сдвигаем все числа, увеличивая на 1 бит.
	Такая система используется во всех современных компьютерах, она удобна для вычислений.
	`Пример: 33 (16 bit) = 100001; -33 (16 bit) = 1111111111011111`

## Перевод чисел в двоичную систему счисления
1. Перевод из 10 в 2:
	1. Раскладываем числа на сумму степеней двоек
	$13=8+4+1=2^3+2^2+2^0$ (8 bit, из 2 в 10)
	2. Каждой степени двойки приравниваем порядковый бит
	$0_7 0_6 0_5 0_4 0_3 0_2 0_1 0_0$
	$2^3+2^2+2^0 = 0_7 0_6 0_5 0_4 1_3 1_2 0_1 1_0$ 
2. Перевод из $2^N$ в 2:
	1. Раскладываем число на составляющие цифры:
	$123_{16}=1_2 2_1 3_0$ (16 bit, из 16 в 2)
	2. Каждую цифру приравниваем к N битам в двоичном коде
	$\begin{cases}1_2=0001\\ 2_1=0010\\ 3_0=0011\end{cases}=>1|0010|0011_2$
3. Перевод из N в 2:
	1. Переводим число из N в 10
	$123_7=1\cdot7^2+2\cdot7^1+3\cdot7^0=66_10$ (8bit, из 7 в 2)
	2. Переводим из 10 в 2
	$66_10=64+2=2^6+2^1=1000010_2$
## Перевод чисел из двоичной системы счисления
1. Перевод из 2 в 10:
	1. Каждой степени двойки приравниваем порядковый бит
	$0_7 0_6 0_5 0_4 0_3 0_2 0_1 0_0$
	$0_7 0_6 0_5 0_4 1_3 1_2 0_1 1_0=2^3+2^2+2^0$ (8bit, из 2 в 10)
	2. Раскладываем числа на сумму степеней двоек
	$2^3+2^2+2^0=8+4+1=13$
2. Перевод из 2 в $2^N$:
	1. Раскладываем число на составляющие N биты:
	$1|0010|0011_2=>\begin{cases}1_2=0001\\ 2_1=0010\\ 3_0=0011\end{cases}$ - (16 bit, из 16 в 2)
	2. Собираем из полученных цифр число
	$1_2 2_1 3_0=123_{16}$
3. Перевод из 2 в N
	1. Переводим из 2 в 10:
	$1000010_2=64+2=2^6+2^1=66_10$ - (8bit, из 2 в 7)
	2. Переводим число из N в 10
	$66_10=1\cdot7^2+2\cdot7^1+3\cdot7^0=123_7$
 